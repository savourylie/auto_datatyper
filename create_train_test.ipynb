{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_raw = pd.DataFrame.from_csv('data_raw/titanic_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_dataset_from_data_column(iterable, label, vector_dim=100, num_rows=5000):\n",
    "    iterable = np.array(iterable)    \n",
    "    choice_range = len(iterable)\n",
    "    iterable_str = iterable.astype(str)\n",
    "    \n",
    "    def contains_time_characters(string):\n",
    "        time_chars = {':', '/', \n",
    "                     'hr', 'hour', 'min', 'minute', 'sec', 'second',\n",
    "                     'day', 'week', 'year'}\n",
    "        for char in time_chars:\n",
    "            if char in string:\n",
    "                return 1\n",
    "        return 0\n",
    "    \n",
    "    vector_list = []\n",
    "    for i in tqdm(list(range(num_rows))):\n",
    "        indices = np.random.choice(choice_range, vector_dim)\n",
    "        stringified_data = iterable_str[indices]\n",
    "        \n",
    "        length_data = np.vectorize(len)(stringified_data)\n",
    "        sum_data = np.vectorize(lambda x: sum([ord(char) for char in x]))(stringified_data)\n",
    "        avg_data = sum_data / length_data\n",
    "        std_data = np.vectorize(lambda x: np.array([ord(char) for char in x]).std())(stringified_data)\n",
    "        float_data = np.vectorize(lambda x: 1 if '.' in x else 0)(stringified_data)\n",
    "        time_data = np.vectorize(contains_time_characters)(stringified_data)\n",
    "        vec = np.concatenate((length_data, sum_data, avg_data, std_data, float_data, time_data))\n",
    "        vector_list.append(vec)\n",
    "        \n",
    "    return np.array(vector_list), np.array([label] * num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:51<00:00, 97.91it/s] \n",
      "100%|██████████| 5000/5000 [00:54<00:00, 92.42it/s] \n",
      "100%|██████████| 5000/5000 [00:49<00:00, 100.62it/s]\n",
      "100%|██████████| 5000/5000 [00:43<00:00, 115.13it/s]\n",
      "100%|██████████| 5000/5000 [01:05<00:00, 75.98it/s]\n",
      "100%|██████████| 5000/5000 [00:54<00:00, 91.67it/s] \n",
      "100%|██████████| 5000/5000 [00:53<00:00, 94.07it/s] \n",
      "100%|██████████| 5000/5000 [01:04<00:00, 77.65it/s] \n",
      "100%|██████████| 5000/5000 [00:47<00:00, 104.25it/s]\n"
     ]
    }
   ],
   "source": [
    "data1 = create_dataset_from_data_column(data_raw['Survived'], 2)\n",
    "data2 = create_dataset_from_data_column(data_raw['Age'], 0)\n",
    "data3 = create_dataset_from_data_column(data_raw['Sex'], 1)\n",
    "data4 = create_dataset_from_data_column(data_raw['Pclass'], 2)\n",
    "data5 = create_dataset_from_data_column(data_raw['Name'], 1)\n",
    "data6 = create_dataset_from_data_column(data_raw['SibSp'], 0)\n",
    "data7 = create_dataset_from_data_column(data_raw['Fare'], 0)\n",
    "data8 = create_dataset_from_data_column(data_raw['Ticket'], 1)\n",
    "data9 = create_dataset_from_data_column(data_raw['Embarked'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, label = np.concatenate((data1[0], data2[0], data3[0], data4[0], data5[0], data6[0], data7[0], data8[0], data9[0]), axis=0), np.concatenate((data1[1], data2[1], data3[1], data4[1], data5[1], data6[1], data7[1], data8[1], data9[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45000, 600), (45000,))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('data/features.pkl', 'wb') as handle:\n",
    "    pickle.dump(features, handle)\n",
    "with open('data/label.pkl', 'wb') as handle:\n",
    "    pickle.dump(label, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45000, 600), (45000,))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=128, n_jobs=-1,\n",
       "            oob_score=False, random_state=1113, verbose=0,\n",
       "            warm_start=False),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, label, test_size=0.3, random_state=1113)\n",
    "\n",
    "ova_clf = OneVsRestClassifier(RandomForestClassifier(n_estimators=128, n_jobs=-1, random_state=1113))\n",
    "ova_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.99992592592592588)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ova_clf.score(X_train, y_train), ova_clf.score(X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.000000000000556"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test) * (1 - ova_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_data_column_type(iterable, estimator, robustness=0.1, vector_dim=100):        \n",
    "    iterable = np.array(iterable)\n",
    "    choice_range = len(iterable)\n",
    "    iterable_str = iterable.astype(str)\n",
    "        \n",
    "    def contains_time_characters(string):\n",
    "        time_chars = {':', '/', \n",
    "                     'hr', 'hour', 'min', 'minute', 'sec', 'second',\n",
    "                     'day', 'week', 'year'}\n",
    "        for char in time_chars:\n",
    "            if char in string:\n",
    "                return 1\n",
    "        return 0\n",
    "    \n",
    "    vector_list = []\n",
    "    for i in (range(int(100 * robustness))):\n",
    "        indices = np.random.choice(choice_range, vector_dim)\n",
    "        stringified_data = iterable_str[indices]\n",
    "        \n",
    "        length_data = np.vectorize(len)(stringified_data)\n",
    "        sum_data = np.vectorize(lambda x: sum([ord(char) for char in x]))(stringified_data)\n",
    "        avg_data = sum_data / length_data\n",
    "        std_data = np.vectorize(lambda x: np.array([ord(char) for char in x]).std())(stringified_data)\n",
    "        float_data = np.vectorize(lambda x: 1 if '.' in x else 0)(stringified_data)\n",
    "        time_data = np.vectorize(contains_time_characters)(stringified_data)\n",
    "        vec = np.concatenate((length_data, sum_data, avg_data, std_data, float_data, time_data))\n",
    "        \n",
    "        vector_list.append(vec)\n",
    "    \n",
    "    prediction = estimator.predict(np.array(vector_list))\n",
    "    prediction_count = Counter(prediction)        \n",
    "    confidence = prediction_count.most_common(1)[0][1] / len(prediction)\n",
    "    decode_dict = {0: 'numeric', 1: 'semantic categorical', 2: 'categorical', 3: 'time'}\n",
    "        \n",
    "    return decode_dict[round(prediction.mean())], confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_column_type_df(data, estimator, robustness=0.1, vector_dim=100):\n",
    "    result_dict = {}\n",
    "    \n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        column_names = data.columns.values\n",
    "        \n",
    "        for i, colname in tqdm(list(enumerate(column_names))):\n",
    "            datatype, confidence = get_data_column_type(data[colname], estimator, robustness=robustness)\n",
    "            result_dict[colname] = datatype, confidence\n",
    "    else:\n",
    "        column_names = list(range(data.shape[1]))\n",
    "        \n",
    "        for i, colname in tqdm(list(enumerate(column_names))):\n",
    "            datatype, confidence = get_data_column_type(data[:, colname], estimator, robustness=robustness)\n",
    "            result_dict[colname] = datatype, confidence\n",
    "    \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:04<00:00,  2.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Age': ('numeric', 1.0),\n",
       " 'Cabin': ('semantic categorical', 1.0),\n",
       " 'Embarked': ('categorical', 1.0),\n",
       " 'Fare': ('numeric', 1.0),\n",
       " 'Name': ('semantic categorical', 1.0),\n",
       " 'Parch': ('numeric', 1.0),\n",
       " 'Pclass': ('categorical', 1.0),\n",
       " 'Sex': ('semantic categorical', 1.0),\n",
       " 'SibSp': ('numeric', 1.0),\n",
       " 'Survived': ('categorical', 1.0),\n",
       " 'Ticket': ('semantic categorical', 1.0)}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data_column_type_df(data_raw, ova_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wine_raw = pd.DataFrame.from_csv('data_raw/winemag-data_first150k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>This tremendous 100% varietal wine hails from ...</td>\n",
       "      <td>Martha's Vineyard</td>\n",
       "      <td>96</td>\n",
       "      <td>235.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Napa Valley</td>\n",
       "      <td>Napa</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>Heitz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Ripe aromas of fig, blackberry and cassis are ...</td>\n",
       "      <td>Carodorum Selección Especial Reserva</td>\n",
       "      <td>96</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Northern Spain</td>\n",
       "      <td>Toro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tinta de Toro</td>\n",
       "      <td>Bodega Carmen Rodríguez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>Mac Watson honors the memory of a wine once ma...</td>\n",
       "      <td>Special Selected Late Harvest</td>\n",
       "      <td>96</td>\n",
       "      <td>90.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Knights Valley</td>\n",
       "      <td>Sonoma</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "      <td>Macauley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>This spent 20 months in 30% new French oak, an...</td>\n",
       "      <td>Reserve</td>\n",
       "      <td>96</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Ponzi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>France</td>\n",
       "      <td>This is the top wine from La Bégude, named aft...</td>\n",
       "      <td>La Brûlade</td>\n",
       "      <td>95</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Provence</td>\n",
       "      <td>Bandol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Provence red blend</td>\n",
       "      <td>Domaine de la Bégude</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country                                        description  \\\n",
       "0      US  This tremendous 100% varietal wine hails from ...   \n",
       "1   Spain  Ripe aromas of fig, blackberry and cassis are ...   \n",
       "2      US  Mac Watson honors the memory of a wine once ma...   \n",
       "3      US  This spent 20 months in 30% new French oak, an...   \n",
       "4  France  This is the top wine from La Bégude, named aft...   \n",
       "\n",
       "                            designation  points  price        province  \\\n",
       "0                     Martha's Vineyard      96  235.0      California   \n",
       "1  Carodorum Selección Especial Reserva      96  110.0  Northern Spain   \n",
       "2         Special Selected Late Harvest      96   90.0      California   \n",
       "3                               Reserve      96   65.0          Oregon   \n",
       "4                            La Brûlade      95   66.0        Provence   \n",
       "\n",
       "            region_1           region_2             variety  \\\n",
       "0        Napa Valley               Napa  Cabernet Sauvignon   \n",
       "1               Toro                NaN       Tinta de Toro   \n",
       "2     Knights Valley             Sonoma     Sauvignon Blanc   \n",
       "3  Willamette Valley  Willamette Valley          Pinot Noir   \n",
       "4             Bandol                NaN  Provence red blend   \n",
       "\n",
       "                    winery  \n",
       "0                    Heitz  \n",
       "1  Bodega Carmen Rodríguez  \n",
       "2                 Macauley  \n",
       "3                    Ponzi  \n",
       "4     Domaine de la Bégude  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'country': ('semantic categorical', 1.0),\n",
       " 'description': ('semantic categorical', 1.0),\n",
       " 'designation': ('semantic categorical', 1.0),\n",
       " 'points': ('categorical', 1.0),\n",
       " 'price': ('numeric', 1.0),\n",
       " 'province': ('semantic categorical', 1.0),\n",
       " 'region_1': ('semantic categorical', 1.0),\n",
       " 'region_2': ('semantic categorical', 1.0),\n",
       " 'variety': ('semantic categorical', 1.0),\n",
       " 'winery': ('semantic categorical', 1.0)}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data_column_type_df(wine_raw, ova_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_raw['points'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [02:43<00:00, 50.32it/s] \n"
     ]
    }
   ],
   "source": [
    "wine_points = create_dataset_from_data_column(wine_raw['points'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features, label = np.concatenate((features, wine_points[0]), axis=0), np.concatenate((label, wine_points[1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 400), (50000,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=128, n_jobs=-1,\n",
       "            oob_score=False, random_state=1113, verbose=0,\n",
       "            warm_start=False),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, label, test_size=0.3, random_state=1113)\n",
    "\n",
    "ova_clf = OneVsRestClassifier(RandomForestClassifier(n_estimators=128, n_jobs=-1, random_state=1113))\n",
    "ova_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.99973333333333336)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = ova_clf.predict(X_test)\n",
    "ova_clf.score(X_train, y_train), ova_clf.score(X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:33<00:00,  3.26s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'country': ('semantic categorical', 1.0),\n",
       " 'description': ('semantic categorical', 1.0),\n",
       " 'designation': ('semantic categorical', 1.0),\n",
       " 'points': ('numeric', 1.0),\n",
       " 'price': ('numeric', 1.0),\n",
       " 'province': ('semantic categorical', 1.0),\n",
       " 'region_1': ('semantic categorical', 1.0),\n",
       " 'region_2': ('semantic categorical', 1.0),\n",
       " 'variety': ('semantic categorical', 1.0),\n",
       " 'winery': ('semantic categorical', 1.0)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data_column_type_df(wine_raw, ova_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ted_raw = pd.DataFrame.from_csv('data_raw/ted_main.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>duration</th>\n",
       "      <th>event</th>\n",
       "      <th>film_date</th>\n",
       "      <th>languages</th>\n",
       "      <th>main_speaker</th>\n",
       "      <th>name</th>\n",
       "      <th>num_speaker</th>\n",
       "      <th>published_date</th>\n",
       "      <th>ratings</th>\n",
       "      <th>related_talks</th>\n",
       "      <th>speaker_occupation</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comments</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4553</th>\n",
       "      <td>Sir Ken Robinson makes an entertaining and pro...</td>\n",
       "      <td>1164</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140825600</td>\n",
       "      <td>60</td>\n",
       "      <td>Ken Robinson</td>\n",
       "      <td>Ken Robinson: Do schools kill creativity?</td>\n",
       "      <td>1</td>\n",
       "      <td>1151367060</td>\n",
       "      <td>[{'id': 7, 'name': 'Funny', 'count': 19645}, {...</td>\n",
       "      <td>[{'id': 865, 'hero': 'https://pe.tedcdn.com/im...</td>\n",
       "      <td>Author/educator</td>\n",
       "      <td>['children', 'creativity', 'culture', 'dance',...</td>\n",
       "      <td>Do schools kill creativity?</td>\n",
       "      <td>https://www.ted.com/talks/ken_robinson_says_sc...</td>\n",
       "      <td>47227110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>With the same humor and humanity he exuded in ...</td>\n",
       "      <td>977</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140825600</td>\n",
       "      <td>43</td>\n",
       "      <td>Al Gore</td>\n",
       "      <td>Al Gore: Averting the climate crisis</td>\n",
       "      <td>1</td>\n",
       "      <td>1151367060</td>\n",
       "      <td>[{'id': 7, 'name': 'Funny', 'count': 544}, {'i...</td>\n",
       "      <td>[{'id': 243, 'hero': 'https://pe.tedcdn.com/im...</td>\n",
       "      <td>Climate advocate</td>\n",
       "      <td>['alternative energy', 'cars', 'climate change...</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>https://www.ted.com/talks/al_gore_on_averting_...</td>\n",
       "      <td>3200520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>New York Times columnist David Pogue takes aim...</td>\n",
       "      <td>1286</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140739200</td>\n",
       "      <td>26</td>\n",
       "      <td>David Pogue</td>\n",
       "      <td>David Pogue: Simplicity sells</td>\n",
       "      <td>1</td>\n",
       "      <td>1151367060</td>\n",
       "      <td>[{'id': 7, 'name': 'Funny', 'count': 964}, {'i...</td>\n",
       "      <td>[{'id': 1725, 'hero': 'https://pe.tedcdn.com/i...</td>\n",
       "      <td>Technology columnist</td>\n",
       "      <td>['computers', 'entertainment', 'interface desi...</td>\n",
       "      <td>Simplicity sells</td>\n",
       "      <td>https://www.ted.com/talks/david_pogue_says_sim...</td>\n",
       "      <td>1636292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>In an emotionally charged talk, MacArthur-winn...</td>\n",
       "      <td>1116</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140912000</td>\n",
       "      <td>35</td>\n",
       "      <td>Majora Carter</td>\n",
       "      <td>Majora Carter: Greening the ghetto</td>\n",
       "      <td>1</td>\n",
       "      <td>1151367060</td>\n",
       "      <td>[{'id': 3, 'name': 'Courageous', 'count': 760}...</td>\n",
       "      <td>[{'id': 1041, 'hero': 'https://pe.tedcdn.com/i...</td>\n",
       "      <td>Activist for environmental justice</td>\n",
       "      <td>['MacArthur grant', 'activism', 'business', 'c...</td>\n",
       "      <td>Greening the ghetto</td>\n",
       "      <td>https://www.ted.com/talks/majora_carter_s_tale...</td>\n",
       "      <td>1697550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>You've never seen data presented like this. Wi...</td>\n",
       "      <td>1190</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140566400</td>\n",
       "      <td>48</td>\n",
       "      <td>Hans Rosling</td>\n",
       "      <td>Hans Rosling: The best stats you've ever seen</td>\n",
       "      <td>1</td>\n",
       "      <td>1151440680</td>\n",
       "      <td>[{'id': 9, 'name': 'Ingenious', 'count': 3202}...</td>\n",
       "      <td>[{'id': 2056, 'hero': 'https://pe.tedcdn.com/i...</td>\n",
       "      <td>Global health expert; data visionary</td>\n",
       "      <td>['Africa', 'Asia', 'Google', 'demo', 'economic...</td>\n",
       "      <td>The best stats you've ever seen</td>\n",
       "      <td>https://www.ted.com/talks/hans_rosling_shows_t...</td>\n",
       "      <td>12005869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                description  duration  \\\n",
       "comments                                                                \n",
       "4553      Sir Ken Robinson makes an entertaining and pro...      1164   \n",
       "265       With the same humor and humanity he exuded in ...       977   \n",
       "124       New York Times columnist David Pogue takes aim...      1286   \n",
       "200       In an emotionally charged talk, MacArthur-winn...      1116   \n",
       "593       You've never seen data presented like this. Wi...      1190   \n",
       "\n",
       "            event   film_date  languages   main_speaker  \\\n",
       "comments                                                  \n",
       "4553      TED2006  1140825600         60   Ken Robinson   \n",
       "265       TED2006  1140825600         43        Al Gore   \n",
       "124       TED2006  1140739200         26    David Pogue   \n",
       "200       TED2006  1140912000         35  Majora Carter   \n",
       "593       TED2006  1140566400         48   Hans Rosling   \n",
       "\n",
       "                                                   name  num_speaker  \\\n",
       "comments                                                               \n",
       "4553          Ken Robinson: Do schools kill creativity?            1   \n",
       "265                Al Gore: Averting the climate crisis            1   \n",
       "124                       David Pogue: Simplicity sells            1   \n",
       "200                  Majora Carter: Greening the ghetto            1   \n",
       "593       Hans Rosling: The best stats you've ever seen            1   \n",
       "\n",
       "          published_date                                            ratings  \\\n",
       "comments                                                                      \n",
       "4553          1151367060  [{'id': 7, 'name': 'Funny', 'count': 19645}, {...   \n",
       "265           1151367060  [{'id': 7, 'name': 'Funny', 'count': 544}, {'i...   \n",
       "124           1151367060  [{'id': 7, 'name': 'Funny', 'count': 964}, {'i...   \n",
       "200           1151367060  [{'id': 3, 'name': 'Courageous', 'count': 760}...   \n",
       "593           1151440680  [{'id': 9, 'name': 'Ingenious', 'count': 3202}...   \n",
       "\n",
       "                                              related_talks  \\\n",
       "comments                                                      \n",
       "4553      [{'id': 865, 'hero': 'https://pe.tedcdn.com/im...   \n",
       "265       [{'id': 243, 'hero': 'https://pe.tedcdn.com/im...   \n",
       "124       [{'id': 1725, 'hero': 'https://pe.tedcdn.com/i...   \n",
       "200       [{'id': 1041, 'hero': 'https://pe.tedcdn.com/i...   \n",
       "593       [{'id': 2056, 'hero': 'https://pe.tedcdn.com/i...   \n",
       "\n",
       "                            speaker_occupation  \\\n",
       "comments                                         \n",
       "4553                           Author/educator   \n",
       "265                           Climate advocate   \n",
       "124                       Technology columnist   \n",
       "200         Activist for environmental justice   \n",
       "593       Global health expert; data visionary   \n",
       "\n",
       "                                                       tags  \\\n",
       "comments                                                      \n",
       "4553      ['children', 'creativity', 'culture', 'dance',...   \n",
       "265       ['alternative energy', 'cars', 'climate change...   \n",
       "124       ['computers', 'entertainment', 'interface desi...   \n",
       "200       ['MacArthur grant', 'activism', 'business', 'c...   \n",
       "593       ['Africa', 'Asia', 'Google', 'demo', 'economic...   \n",
       "\n",
       "                                    title  \\\n",
       "comments                                    \n",
       "4553          Do schools kill creativity?   \n",
       "265           Averting the climate crisis   \n",
       "124                      Simplicity sells   \n",
       "200                   Greening the ghetto   \n",
       "593       The best stats you've ever seen   \n",
       "\n",
       "                                                        url     views  \n",
       "comments                                                               \n",
       "4553      https://www.ted.com/talks/ken_robinson_says_sc...  47227110  \n",
       "265       https://www.ted.com/talks/al_gore_on_averting_...   3200520  \n",
       "124       https://www.ted.com/talks/david_pogue_says_sim...   1636292  \n",
       "200       https://www.ted.com/talks/majora_carter_s_tale...   1697550  \n",
       "593       https://www.ted.com/talks/hans_rosling_shows_t...  12005869  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ted_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:09<00:00,  1.77it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'description': ('semantic categorical', 1.0),\n",
       " 'duration': ('numeric', 1.0),\n",
       " 'event': ('semantic categorical', 1.0),\n",
       " 'film_date': ('time', 1.0),\n",
       " 'languages': ('categorical', 1.0),\n",
       " 'main_speaker': ('semantic categorical', 1.0),\n",
       " 'name': ('semantic categorical', 1.0),\n",
       " 'num_speaker': ('numeric', 1.0),\n",
       " 'published_date': ('time', 1.0),\n",
       " 'ratings': ('semantic categorical', 1.0),\n",
       " 'related_talks': ('semantic categorical', 1.0),\n",
       " 'speaker_occupation': ('semantic categorical', 1.0),\n",
       " 'tags': ('semantic categorical', 1.0),\n",
       " 'title': ('semantic categorical', 1.0),\n",
       " 'url': ('semantic categorical', 1.0),\n",
       " 'views': ('numeric', 1.0)}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data_column_type_df(ted_raw, ova_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ted_raw['num_speaker'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [01:12<00:00, 68.94it/s] \n",
      "100%|██████████| 5000/5000 [00:45<00:00, 110.63it/s]\n",
      "100%|██████████| 5000/5000 [00:46<00:00, 107.20it/s]\n",
      "100%|██████████| 5000/5000 [00:51<00:00, 97.32it/s] \n",
      "100%|██████████| 5000/5000 [00:53<00:00, 93.71it/s] \n"
     ]
    }
   ],
   "source": [
    "film_date = create_dataset_from_data_column(ted_raw['film_date'], 3)\n",
    "languages = create_dataset_from_data_column(ted_raw['languages'], 2)\n",
    "num_speaker = create_dataset_from_data_column(ted_raw['num_speaker'], 0)\n",
    "published_date = create_dataset_from_data_column(ted_raw['published_date'], 3)\n",
    "views = create_dataset_from_data_column(ted_raw['views'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features, label = np.concatenate((features, film_date[0], languages[0], num_speaker[0], published_date[0], views[0]), axis=0), np.concatenate((label, film_date[1], languages[1], num_speaker[1], published_date[1], views[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75000, 400), (75000,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=128, n_jobs=-1,\n",
       "            oob_score=False, random_state=1113, verbose=0,\n",
       "            warm_start=False),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, label, test_size=0.3, random_state=1113)\n",
    "\n",
    "ova_clf = OneVsRestClassifier(RandomForestClassifier(n_estimators=128, n_jobs=-1, random_state=1113))\n",
    "ova_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.99986666666666668)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = ova_clf.predict(X_test)\n",
    "ova_clf.score(X_train, y_train), ova_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:34<00:00,  6.03s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'description': ('semantic categorical', 1.0),\n",
       " 'duration': ('numeric', 1.0),\n",
       " 'event': ('semantic categorical', 1.0),\n",
       " 'film_date': ('time', 1.0),\n",
       " 'languages': ('categorical', 1.0),\n",
       " 'main_speaker': ('semantic categorical', 1.0),\n",
       " 'name': ('semantic categorical', 1.0),\n",
       " 'num_speaker': ('numeric', 1.0),\n",
       " 'published_date': ('time', 1.0),\n",
       " 'ratings': ('semantic categorical', 1.0),\n",
       " 'related_talks': ('semantic categorical', 1.0),\n",
       " 'speaker_occupation': ('semantic categorical', 1.0),\n",
       " 'tags': ('semantic categorical', 1.0),\n",
       " 'title': ('semantic categorical', 1.0),\n",
       " 'url': ('semantic categorical', 1.0),\n",
       " 'views': ('numeric', 1.0)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data_column_type_df(ted_raw, ova_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 878: expected 11 fields, saw 12\\nSkipping line 1713: expected 11 fields, saw 12\\nSkipping line 1815: expected 11 fields, saw 12\\nSkipping line 2858: expected 11 fields, saw 12\\nSkipping line 3734: expected 11 fields, saw 12\\nSkipping line 4756: expected 11 fields, saw 12\\nSkipping line 5389: expected 11 fields, saw 12\\nSkipping line 5423: expected 11 fields, saw 12\\nSkipping line 5614: expected 11 fields, saw 12\\nSkipping line 5849: expected 11 fields, saw 12\\nSkipping line 6093: expected 11 fields, saw 12\\nSkipping line 7516: expected 11 fields, saw 12\\nSkipping line 7626: expected 11 fields, saw 12\\nSkipping line 8893: expected 11 fields, saw 12\\nSkipping line 9015: expected 11 fields, saw 12\\nSkipping line 9571: expected 11 fields, saw 12\\nSkipping line 9620: expected 11 fields, saw 12\\nSkipping line 9751: expected 11 fields, saw 12\\nSkipping line 10157: expected 11 fields, saw 12\\nSkipping line 10427: expected 11 fields, saw 12\\nSkipping line 12035: expected 11 fields, saw 12\\nSkipping line 12113: expected 11 fields, saw 12\\nSkipping line 12144: expected 11 fields, saw 12\\nSkipping line 12891: expected 11 fields, saw 12\\nSkipping line 14613: expected 11 fields, saw 12\\nSkipping line 16031: expected 11 fields, saw 12\\nSkipping line 16344: expected 11 fields, saw 12\\nSkipping line 16399: expected 11 fields, saw 12\\nSkipping line 16635: expected 11 fields, saw 12\\nSkipping line 16722: expected 11 fields, saw 12\\nSkipping line 18241: expected 11 fields, saw 12\\nSkipping line 18367: expected 11 fields, saw 12\\nSkipping line 18479: expected 11 fields, saw 12\\nSkipping line 19814: expected 11 fields, saw 12\\nSkipping line 19859: expected 11 fields, saw 12\\nSkipping line 19909: expected 11 fields, saw 12\\nSkipping line 19935: expected 11 fields, saw 12\\nSkipping line 20386: expected 11 fields, saw 12\\nSkipping line 20533: expected 11 fields, saw 12\\nSkipping line 20764: expected 11 fields, saw 12\\nSkipping line 21145: expected 11 fields, saw 12\\nSkipping line 21291: expected 11 fields, saw 12\\nSkipping line 21309: expected 11 fields, saw 12\\nSkipping line 21576: expected 11 fields, saw 12\\nSkipping line 21966: expected 11 fields, saw 12\\nSkipping line 22092: expected 11 fields, saw 12\\nSkipping line 22108: expected 11 fields, saw 12\\nSkipping line 22236: expected 11 fields, saw 12\\nSkipping line 22785: expected 11 fields, saw 12\\nSkipping line 23143: expected 11 fields, saw 12\\nSkipping line 23145: expected 11 fields, saw 12\\nSkipping line 23251: expected 11 fields, saw 12\\nSkipping line 23369: expected 11 fields, saw 12\\nSkipping line 23464: expected 11 fields, saw 12\\nSkipping line 23622: expected 11 fields, saw 12\\nSkipping line 23732: expected 11 fields, saw 12\\nSkipping line 23924: expected 11 fields, saw 12\\nSkipping line 24696: expected 11 fields, saw 12\\nSkipping line 25543: expected 11 fields, saw 12\\nSkipping line 25703: expected 11 fields, saw 12\\nSkipping line 25815: expected 11 fields, saw 12\\nSkipping line 26185: expected 11 fields, saw 12\\nSkipping line 27424: expected 11 fields, saw 12\\nSkipping line 27465: expected 11 fields, saw 12\\nSkipping line 28083: expected 11 fields, saw 12\\nSkipping line 28282: expected 11 fields, saw 12\\nSkipping line 28460: expected 11 fields, saw 12\\nSkipping line 28745: expected 11 fields, saw 12\\nSkipping line 29674: expected 11 fields, saw 12\\nSkipping line 30342: expected 11 fields, saw 12\\nSkipping line 30417: expected 11 fields, saw 12\\nSkipping line 31154: expected 11 fields, saw 12\\nSkipping line 31308: expected 11 fields, saw 12\\nSkipping line 32198: expected 11 fields, saw 12\\nSkipping line 32439: expected 11 fields, saw 12\\nSkipping line 32675: expected 11 fields, saw 12\\nSkipping line 33134: expected 11 fields, saw 12\\nSkipping line 33442: expected 11 fields, saw 12\\nSkipping line 34184: expected 11 fields, saw 12\\nSkipping line 34731: expected 11 fields, saw 12\\nSkipping line 34869: expected 11 fields, saw 12\\nSkipping line 35107: expected 11 fields, saw 12\\nSkipping line 35300: expected 11 fields, saw 12\\nSkipping line 35396: expected 11 fields, saw 12\\nSkipping line 35913: expected 11 fields, saw 12\\nSkipping line 36445: expected 11 fields, saw 12\\nSkipping line 36693: expected 11 fields, saw 12\\nSkipping line 36723: expected 11 fields, saw 12\\nSkipping line 37293: expected 11 fields, saw 12\\nSkipping line 37361: expected 11 fields, saw 12\\nSkipping line 37980: expected 11 fields, saw 12\\nSkipping line 38090: expected 11 fields, saw 12\\nSkipping line 38197: expected 11 fields, saw 12\\nSkipping line 39431: expected 11 fields, saw 12\\nSkipping line 39598: expected 11 fields, saw 12\\nSkipping line 39679: expected 11 fields, saw 12\\nSkipping line 39794: expected 11 fields, saw 12\\nSkipping line 40021: expected 11 fields, saw 12\\nSkipping line 40430: expected 11 fields, saw 12\\nSkipping line 42858: expected 11 fields, saw 12\\nSkipping line 43662: expected 11 fields, saw 12\\nSkipping line 44162: expected 11 fields, saw 12\\nSkipping line 45529: expected 11 fields, saw 12\\nSkipping line 46678: expected 11 fields, saw 12\\nSkipping line 46788: expected 11 fields, saw 12\\nSkipping line 46811: expected 11 fields, saw 12\\nSkipping line 46924: expected 11 fields, saw 12\\nSkipping line 47287: expected 11 fields, saw 12\\nSkipping line 47377: expected 11 fields, saw 12\\nSkipping line 47419: expected 11 fields, saw 12\\nSkipping line 47492: expected 11 fields, saw 12\\nSkipping line 47629: expected 11 fields, saw 12\\nSkipping line 48125: expected 11 fields, saw 12\\nSkipping line 48932: expected 11 fields, saw 12\\nSkipping line 48971: expected 11 fields, saw 12\\nSkipping line 49440: expected 11 fields, saw 12\\nSkipping line 49457: expected 11 fields, saw 12\\nSkipping line 50670: expected 11 fields, saw 12\\nSkipping line 50960: expected 11 fields, saw 12\\nSkipping line 51275: expected 11 fields, saw 12\\nSkipping line 51649: expected 11 fields, saw 12\\nSkipping line 51993: expected 11 fields, saw 12\\nSkipping line 52023: expected 11 fields, saw 12\\nSkipping line 52059: expected 11 fields, saw 12\\nSkipping line 52259: expected 11 fields, saw 12\\nSkipping line 52368: expected 11 fields, saw 12\\nSkipping line 52783: expected 11 fields, saw 12\\nSkipping line 53064: expected 11 fields, saw 12\\nSkipping line 53135: expected 11 fields, saw 12\\nSkipping line 53514: expected 11 fields, saw 12\\nSkipping line 54092: expected 11 fields, saw 12\\nSkipping line 55403: expected 11 fields, saw 12\\nSkipping line 57476: expected 11 fields, saw 12\\nSkipping line 58646: expected 11 fields, saw 12\\nSkipping line 58808: expected 11 fields, saw 12\\nSkipping line 59119: expected 11 fields, saw 12\\nSkipping line 59727: expected 11 fields, saw 12\\nSkipping line 60386: expected 11 fields, saw 12\\nSkipping line 60478: expected 11 fields, saw 12\\nSkipping line 60542: expected 11 fields, saw 12\\nSkipping line 60913: expected 11 fields, saw 12\\nSkipping line 61032: expected 11 fields, saw 12\\nSkipping line 61640: expected 11 fields, saw 12\\nSkipping line 61732: expected 11 fields, saw 12\\nSkipping line 62029: expected 11 fields, saw 12\\nSkipping line 62219: expected 11 fields, saw 12\\nSkipping line 63657: expected 11 fields, saw 12\\nSkipping line 64712: expected 11 fields, saw 12\\n'\n",
      "b'Skipping line 65881: expected 11 fields, saw 12\\nSkipping line 66093: expected 11 fields, saw 12\\nSkipping line 66095: expected 11 fields, saw 12\\nSkipping line 66476: expected 11 fields, saw 12\\nSkipping line 66549: expected 11 fields, saw 12\\nSkipping line 66550: expected 11 fields, saw 12\\nSkipping line 68102: expected 11 fields, saw 12\\nSkipping line 69441: expected 11 fields, saw 12\\nSkipping line 70104: expected 11 fields, saw 12\\nSkipping line 70452: expected 11 fields, saw 12\\nSkipping line 70642: expected 11 fields, saw 12\\nSkipping line 70644: expected 11 fields, saw 12\\nSkipping line 70716: expected 11 fields, saw 12\\nSkipping line 71345: expected 11 fields, saw 12\\nSkipping line 71634: expected 11 fields, saw 12\\nSkipping line 72091: expected 11 fields, saw 12\\nSkipping line 72119: expected 11 fields, saw 12\\nSkipping line 73543: expected 11 fields, saw 12\\nSkipping line 74654: expected 11 fields, saw 12\\nSkipping line 74785: expected 11 fields, saw 12\\nSkipping line 74918: expected 11 fields, saw 12\\nSkipping line 75062: expected 11 fields, saw 12\\nSkipping line 75346: expected 11 fields, saw 12\\nSkipping line 75416: expected 11 fields, saw 12\\nSkipping line 75677: expected 11 fields, saw 12\\nSkipping line 75833: expected 11 fields, saw 12\\nSkipping line 76117: expected 11 fields, saw 12\\nSkipping line 76834: expected 11 fields, saw 12\\nSkipping line 77540: expected 11 fields, saw 12\\nSkipping line 77568: expected 11 fields, saw 12\\nSkipping line 77607: expected 11 fields, saw 12\\nSkipping line 77871: expected 11 fields, saw 12\\nSkipping line 78117: expected 11 fields, saw 12\\nSkipping line 78526: expected 11 fields, saw 12\\nSkipping line 78605: expected 11 fields, saw 12\\nSkipping line 79151: expected 11 fields, saw 12\\nSkipping line 79945: expected 11 fields, saw 12\\nSkipping line 80156: expected 11 fields, saw 12\\nSkipping line 80328: expected 11 fields, saw 12\\nSkipping line 80382: expected 11 fields, saw 12\\nSkipping line 80421: expected 11 fields, saw 12\\nSkipping line 80503: expected 11 fields, saw 12\\nSkipping line 82071: expected 11 fields, saw 12\\nSkipping line 82566: expected 11 fields, saw 12\\nSkipping line 86123: expected 11 fields, saw 12\\nSkipping line 87218: expected 11 fields, saw 12\\nSkipping line 87457: expected 11 fields, saw 12\\nSkipping line 87579: expected 11 fields, saw 12\\n'\n",
      "/Users/calvinku/anaconda/envs/python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (5,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "ufo_raw = pd.read_csv('data_raw/ufo-sightings.csv', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration (seconds)</th>\n",
       "      <th>duration (hours/min)</th>\n",
       "      <th>comments</th>\n",
       "      <th>date posted</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/10/1949 20:30</td>\n",
       "      <td>san marcos</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>cylinder</td>\n",
       "      <td>2700</td>\n",
       "      <td>45 minutes</td>\n",
       "      <td>This event took place in early fall around 194...</td>\n",
       "      <td>4/27/2004</td>\n",
       "      <td>29.8830556</td>\n",
       "      <td>-97.941111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/10/1949 21:00</td>\n",
       "      <td>lackland afb</td>\n",
       "      <td>tx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>light</td>\n",
       "      <td>7200</td>\n",
       "      <td>1-2 hrs</td>\n",
       "      <td>1949 Lackland AFB&amp;#44 TX.  Lights racing acros...</td>\n",
       "      <td>12/16/2005</td>\n",
       "      <td>29.38421</td>\n",
       "      <td>-98.581082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/10/1955 17:00</td>\n",
       "      <td>chester (uk/england)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gb</td>\n",
       "      <td>circle</td>\n",
       "      <td>20</td>\n",
       "      <td>20 seconds</td>\n",
       "      <td>Green/Orange circular disc over Chester&amp;#44 En...</td>\n",
       "      <td>1/21/2008</td>\n",
       "      <td>53.2</td>\n",
       "      <td>-2.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/10/1956 21:00</td>\n",
       "      <td>edna</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>circle</td>\n",
       "      <td>20</td>\n",
       "      <td>1/2 hour</td>\n",
       "      <td>My older brother and twin sister were leaving ...</td>\n",
       "      <td>1/17/2004</td>\n",
       "      <td>28.9783333</td>\n",
       "      <td>-96.645833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/10/1960 20:00</td>\n",
       "      <td>kaneohe</td>\n",
       "      <td>hi</td>\n",
       "      <td>us</td>\n",
       "      <td>light</td>\n",
       "      <td>900</td>\n",
       "      <td>15 minutes</td>\n",
       "      <td>AS a Marine 1st Lt. flying an FJ4B fighter/att...</td>\n",
       "      <td>1/22/2004</td>\n",
       "      <td>21.4180556</td>\n",
       "      <td>-157.803611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           datetime                  city state country     shape  \\\n",
       "0  10/10/1949 20:30            san marcos    tx      us  cylinder   \n",
       "1  10/10/1949 21:00          lackland afb    tx     NaN     light   \n",
       "2  10/10/1955 17:00  chester (uk/england)   NaN      gb    circle   \n",
       "3  10/10/1956 21:00                  edna    tx      us    circle   \n",
       "4  10/10/1960 20:00               kaneohe    hi      us     light   \n",
       "\n",
       "  duration (seconds) duration (hours/min)  \\\n",
       "0               2700           45 minutes   \n",
       "1               7200              1-2 hrs   \n",
       "2                 20           20 seconds   \n",
       "3                 20             1/2 hour   \n",
       "4                900           15 minutes   \n",
       "\n",
       "                                            comments date posted    latitude  \\\n",
       "0  This event took place in early fall around 194...   4/27/2004  29.8830556   \n",
       "1  1949 Lackland AFB&#44 TX.  Lights racing acros...  12/16/2005    29.38421   \n",
       "2  Green/Orange circular disc over Chester&#44 En...   1/21/2008        53.2   \n",
       "3  My older brother and twin sister were leaving ...   1/17/2004  28.9783333   \n",
       "4  AS a Marine 1st Lt. flying an FJ4B fighter/att...   1/22/2004  21.4180556   \n",
       "\n",
       "    longitude  \n",
       "0  -97.941111  \n",
       "1  -98.581082  \n",
       "2   -2.916667  \n",
       "3  -96.645833  \n",
       "4 -157.803611  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufo_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:06<00:00,  1.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'city': ('semantic categorical', 1.0),\n",
       " 'comments': ('semantic categorical', 1.0),\n",
       " 'country': ('numeric', 1.0),\n",
       " 'date posted': ('time', 1.0),\n",
       " 'datetime': ('time', 0.8),\n",
       " 'duration (hours/min)': ('semantic categorical', 1.0),\n",
       " 'duration (seconds)': ('categorical', 1.0),\n",
       " 'latitude': ('time', 1.0),\n",
       " 'longitude': ('time', 1.0),\n",
       " 'shape': ('semantic categorical', 1.0),\n",
       " 'state': ('semantic categorical', 1.0)}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data_column_type_df(ufo_raw, ova_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
